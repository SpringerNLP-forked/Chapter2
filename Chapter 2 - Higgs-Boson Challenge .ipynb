{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages and verify versions\n",
    "\n",
    "# numpy\n",
    "import numpy\n",
    "print('numpy: %s' % numpy.__version__)\n",
    "# scipy\n",
    "import scipy\n",
    "print('scipy: %s' % scipy.__version__)\n",
    "# matplotlib\n",
    "import matplotlib\n",
    "print('matplotlib: %s' % matplotlib.__version__)\n",
    "# pandas\n",
    "import pandas\n",
    "print('pandas: %s' % pandas.__version__)\n",
    "# scikit-learn\n",
    "import sklearn\n",
    "print('sklearn: %s' % sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Case Study : Higgs Bosson Challenge \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The challenge data is now available on http://opendata.cern.ch/collection/ATLAS-Higgs-Challenge-2014. The case study is to classify the events into signals and background, any other event other than the signal. This is a binary classification problem. Instead of the entire data set, we have used a sample data set which has training data size of 10000 and a separate testing data of size 5000 with labels on which models will be evaluated. We will also assume the best model is selected based on the classification accuracy achieved on the test data, with metrics of accuracy, as the data is well balanced between the two classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading Training and Testing CSV files using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "train_file = './data/higgs_train_10k.csv'\n",
    "test_file = './data/higgs_test_5k.csv'\n",
    "names = [\n",
    "    'response',\n",
    "    'x1',\n",
    "    'x2',\n",
    "    'x3',\n",
    "    'x4',\n",
    "    'x5',\n",
    "    'x6',\n",
    "    'x7',\n",
    "    'x8',\n",
    "    'x9',\n",
    "    'x10',\n",
    "    'x11',\n",
    "    'x12',\n",
    "    'x13',\n",
    "    'x14',\n",
    "    'x15',\n",
    "    'x16',\n",
    "    'x17',\n",
    "    'x18',\n",
    "    'x19',\n",
    "    'x20',\n",
    "    'x21',\n",
    "    'x22',\n",
    "    'x23',\n",
    "    'x24',\n",
    "    'x25',\n",
    "    'x26',\n",
    "    'x27',\n",
    "    'x28']\n",
    "train_data = read_csv(train_file, names=names)\n",
    "test_data = read_csv(test_file, names=names)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give the peek into the dataset\n",
    "peek = train_data.head(20)\n",
    "print(peek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datatype of each feataure\n",
    "types = train_data.dtypes\n",
    "print(types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base statistics for data\n",
    "from pandas import set_option\n",
    "set_option('display.width', 100)\n",
    "set_option('precision', 5)\n",
    "description = train_data.describe()\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class distribution for train and test\n",
    "train_data_class = train_data.groupby('response').size()\n",
    "print(train_data_class)\n",
    "test_data_class = test_data.groupby('response').size()\n",
    "print(test_data_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pearsons correlation to understand feature independence\n",
    "correlations = train_data.corr(method='pearson')\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualization of correlations\n",
    "import matplotlib.pyplot as pyplot\n",
    "fig = pyplot.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(correlations, vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "ticks = numpy.arange(0,29,1)\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_xticklabels(names)\n",
    "ax.set_yticklabels(names)\n",
    "pyplot.rcParams['figure.figsize'] = (27,27)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization using pyplot and histograms of training and testing data\n",
    "from matplotlib import pyplot\n",
    "pyplot.rcParams['figure.figsize'] = (13,13)\n",
    "train_data.hist()\n",
    "pyplot.show()\n",
    "test_data.hist()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot visualization of train and test data\n",
    "pyplot.rcParams['figure.figsize'] = (12,12)\n",
    "train_data.plot(kind='box', subplots=True, layout=(6,6), sharex=False, sharey=False)\n",
    "pyplot.show()\n",
    "test_data.plot(kind='box', subplots=True, layout=(6,6), sharex=False, sharey=False)\n",
    "pyplot.rcParams['figure.figsize'] = (12,12)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train and Test Data as Vector/Matrix Representation for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "train_array = train_data.values\n",
    "# separate array into input and output variables\n",
    "X_train = train_array[:,1:28]\n",
    "y_train = train_array[:,0]\n",
    "# test data\n",
    "test_array = test_data.values\n",
    "# separate array into input and output variables\n",
    "X_test = test_array[:,1:28]\n",
    "y_test = test_array[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manifold Visualization of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.ticker import NullFormatter\n",
    "\n",
    "from sklearn import manifold\n",
    "methods = ['standard', 'ltsa', 'hessian', 'modified']\n",
    "labels = ['LLE', 'LTSA', 'Hessian LLE', 'Modified LLE']\n",
    "\n",
    "n_neighbors = 10\n",
    "n_components = 2\n",
    "color=y_train\n",
    "\n",
    "for i, method in enumerate(methods):\n",
    "    t0 = time()\n",
    "    Ytransformed = manifold.Isomap(n_neighbors, n_components).fit_transform(X_train)\n",
    "    t1 = time()\n",
    "    print(\"Isomap: %.2g sec\" % (t1 - t0))\n",
    "    ax = fig.add_subplot(257)\n",
    "    plt.scatter(Ytransformed[:, 0], Ytransformed[:, 1],c=color, cmap=plt.cm.Spectral)\n",
    "    plt.title(labels[i])\n",
    "    ax.xaxis.set_major_formatter(NullFormatter())\n",
    "    ax.yaxis.set_major_formatter(NullFormatter())\n",
    "    plt.axis('tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "t0 = time()\n",
    "mds = manifold.MDS(n_components, max_iter=100, n_init=1)\n",
    "Ytransformed = mds.fit_transform(X_train)\n",
    "t1 = time()\n",
    "print(\"MDS: %.2g sec\" % (t1 - t0))\n",
    "ax = fig.add_subplot(258)\n",
    "plt.scatter(Ytransformed[:, 0], Ytransformed[:, 1], c=color,cmap=plt.cm.Spectral)\n",
    "plt.title(\"MDS (%.2g sec)\" % (t1 - t0))\n",
    "ax.xaxis.set_major_formatter(NullFormatter())\n",
    "ax.yaxis.set_major_formatter(NullFormatter())\n",
    "plt.axis('tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "t0 = time()\n",
    "se = manifold.SpectralEmbedding(n_components=n_components,\n",
    "                                n_neighbors=n_neighbors)\n",
    "Ytransformed = se.fit_transform(X_train)\n",
    "t1 = time()\n",
    "print(\"SpectralEmbedding: %.2g sec\" % (t1 - t0))\n",
    "ax = fig.add_subplot(259)\n",
    "plt.scatter(Ytransformed[:, 0], Ytransformed[:, 1], c=color,cmap=plt.cm.Spectral)\n",
    "plt.title(\"SpectralEmbedding (%.2g sec)\" % (t1 - t0))\n",
    "ax.xaxis.set_major_formatter(NullFormatter())\n",
    "ax.yaxis.set_major_formatter(NullFormatter())\n",
    "plt.axis('tight')\n",
    "plt.show()\n",
    "\n",
    "t0 = time()\n",
    "tsne = manifold.TSNE(n_components=n_components, init='pca', random_state=0)\n",
    "Ytransformed = tsne.fit_transform(X_train)\n",
    "t1 = time()\n",
    "print(\"t-SNE: %.2g sec\" % (t1 - t0))\n",
    "ax = fig.add_subplot(2, 5, 10)\n",
    "plt.scatter(Ytransformed[:, 0], Ytransformed[:, 1], c=color,cmap=plt.cm.Spectral)\n",
    "plt.title(\"t-SNE (%.2g sec)\" % (t1 - t0))\n",
    "ax.xaxis.set_major_formatter(NullFormatter())\n",
    "ax.yaxis.set_major_formatter(NullFormatter())\n",
    "plt.axis('tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Feature Transformation using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature decomposition  with PCA\n",
    "from sklearn.decomposition import PCA\n",
    "# feature extraction\n",
    "pca = PCA(n_components=2)\n",
    "fit = pca.fit(X_train)\n",
    "projected = pca.fit_transform(X_train)\n",
    "\n",
    "pyplot.scatter(projected[:, 0], projected[:, 1],\n",
    "               c=y_train, edgecolor='none', alpha=0.5)\n",
    "pyplot.xlabel('PCA component 1')\n",
    "pyplot.ylabel('PCA component 2')\n",
    "pyplot.rcParams['figure.figsize'] = (8, 8)\n",
    "pyplot.colorbar()\n",
    "pyplot.show()\n",
    "pca = PCA(n_components=25)\n",
    "fit = pca.fit(X_train)\n",
    "pyplot.plot(numpy.cumsum(fit.explained_variance_ratio_))\n",
    "pyplot.xlabel('number of components')\n",
    "pyplot.ylabel('cumulative explained variance')\n",
    "pyplot.show()\n",
    "# summarize components\n",
    "print(\"Explained Variance: %s\" % fit.explained_variance_ratio_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Feature Selection impact and scores on Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "scaler = min_max_scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "chi2_score = chi2(X_train_scaled, y_train)[0]\n",
    "features = [\n",
    "    'x1',\n",
    "    'x2',\n",
    "    'x3',\n",
    "    'x4',\n",
    "    'x5',\n",
    "    'x6',\n",
    "    'x7',\n",
    "    'x8',\n",
    "    'x9',\n",
    "    'x10',\n",
    "    'x11',\n",
    "    'x12',\n",
    "    'x13',\n",
    "    'x14',\n",
    "    'x15',\n",
    "    'x16',\n",
    "    'x17',\n",
    "    'x18',\n",
    "    'x19',\n",
    "    'x20',\n",
    "    'x21',\n",
    "    'x22',\n",
    "    'x23',\n",
    "    'x24',\n",
    "    'x25',\n",
    "    'x26',\n",
    "    'x27',\n",
    "    'x28']\n",
    "fscores = zip(features, chi2_score)\n",
    "wchi2 = sorted(fscores, key=lambda x: x[1], reverse=True)\n",
    "scores_labels = numpy.asarray(wchi2)\n",
    "print(scores_labels)\n",
    "label = [row[0] for row in scores_labels]\n",
    "print(label)\n",
    "score = [row[1] for row in scores_labels]\n",
    "print(score)\n",
    "y_pos = numpy.arange(len(score))\n",
    "yrange = range(len(score))\n",
    "print(yrange)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Model Creation, Tuning Hyperparameters and Validation using Train Data¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform grid search to find the best parameter for Logistic Regression,\n",
    "# Perceptron, Naive Bayes, LDA algorithm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# using roc AUC as scoring\n",
    "scoring = 'accuracy'\n",
    "\n",
    "# Naive Bayes\n",
    "naiveBayes = GaussianNB()\n",
    "nbscore = cross_val_score(naiveBayes, X_train, y_train, cv=3, scoring=scoring)\n",
    "print('Naive Bayes CV score =', np.mean(nbscore))\n",
    "\n",
    "\n",
    "# penalty\n",
    "penalties = numpy.array(['l1', 'l2'])\n",
    "# C for logistic regression\n",
    "c_values = numpy.array([1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001, 0.00001])\n",
    "# max iteration\n",
    "iters = numpy.array([100, 150])\n",
    "LR_param_grid = {'penalty': penalties, 'C': c_values, 'max_iter': iters}\n",
    "\n",
    "# logistic regression as algorithm\n",
    "gridLogisticRegression = LogisticRegression()\n",
    "# Using GridSearchCV on Training Data for LR\n",
    "grid = GridSearchCV(\n",
    "    estimator=gridLogisticRegression,\n",
    "    param_grid=LR_param_grid,\n",
    "    scoring=scoring)\n",
    "grid.fit(X_train, y_train)\n",
    "print('LR CVScore ', grid.best_score_)\n",
    "print('LR Penalty', grid.best_estimator_.penalty)\n",
    "print('LR C', grid.best_estimator_.C)\n",
    "print('LR Max Iterations', grid.best_estimator_.max_iter)\n",
    "\n",
    "\n",
    "# Perceptron\n",
    "# Using GridSearchCV on Training Data for perceptron\n",
    "# alphas\n",
    "alphas = numpy.array([0.001, 0.0001, 0.00001, 0.000001])\n",
    "# iterations\n",
    "pereptorn_param_grid = {'alpha': alphas, 'max_iter': iters}\n",
    "grid = GridSearchCV(\n",
    "    estimator=Perceptron(),\n",
    "    param_grid=pereptorn_param_grid,\n",
    "    scoring=scoring)\n",
    "grid.fit(X_train, y_train)\n",
    "print('Perceptron CVScore ', grid.best_score_)\n",
    "print('Perceptron alpha', grid.best_estimator_.alpha)\n",
    "print('Perceptron Max Iterations', grid.best_estimator_.max_iter)\n",
    "\n",
    "# LDA\n",
    "tols = numpy.array([0.001, 0.00001, 0.001])\n",
    "lda_param_grid = {'tol': tols}\n",
    "grid = GridSearchCV(\n",
    "    estimator=LinearDiscriminantAnalysis(),\n",
    "    param_grid=lda_param_grid,\n",
    "    scoring=scoring)\n",
    "grid.fit(X_train, y_train)\n",
    "print('LDA CVScore ', grid.best_score_)\n",
    "print('LDA tol', grid.best_estimator_.tol)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. SVM Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "import numpy\n",
    "# gamma parameter in SVM\n",
    "gammas = numpy.array([1, 0.1, 0.01, 0.001])\n",
    "# C for logistic regression\n",
    "c_values = numpy.array([100, 1, 0.1, 0.01])\n",
    "svm_param_grid = {'gamma': gammas, 'C': c_values}\n",
    "svm = SVC(kernel='rbf')\n",
    "scoring = 'accuracy'\n",
    "grid = GridSearchCV(estimator=svm, param_grid=svm_param_grid, scoring=scoring)\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.gamma)\n",
    "print(grid.best_estimator_.C)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Pipeline with Feature Reduction Selection, Logistic Regression using Grid Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified the Code for changes\n",
    "# Original Authors: Robert McGibbon, Joel Nothman, Guillaume Lemaitre\n",
    "\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# transform the features using MinMaxScaler as many are negatives\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "scaler = min_max_scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('reduce_dim', PCA()),\n",
    "    ('classify', LogisticRegression())\n",
    "])\n",
    "\n",
    "N_FEATURES_OPTIONS = [10, 15, 20]\n",
    "C_OPTIONS = [0.001, 0.1, 1, 10, 100, 1000]\n",
    "max_iter_OPTIONS = [100, 150]\n",
    "param_grid = [\n",
    "    {\n",
    "        'reduce_dim': [PCA(iterated_power=10)],\n",
    "        'reduce_dim__n_components': N_FEATURES_OPTIONS,\n",
    "        'classify__C': C_OPTIONS,\n",
    "        'classify__max_iter':max_iter_OPTIONS\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [SelectKBest(chi2)],\n",
    "        'reduce_dim__k': N_FEATURES_OPTIONS,\n",
    "        'classify__C': C_OPTIONS,\n",
    "        'classify__max_iter':max_iter_OPTIONS\n",
    "    },\n",
    "]\n",
    "reducer_labels = ['PCA', 'KBest(chi2)']\n",
    "\n",
    "grid = GridSearchCV(pipe, cv=3, n_jobs=1, param_grid=param_grid)\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "mean_scores = np.array(grid.cv_results_['mean_test_score'])\n",
    "# scores are in the order of param_grid iteration, which is alphabetical\n",
    "mean_scores = mean_scores.reshape(len(C_OPTIONS), -1, len(N_FEATURES_OPTIONS))\n",
    "# select score for best C\n",
    "mean_scores = mean_scores.max(axis=0)\n",
    "bar_offsets = (np.arange(len(N_FEATURES_OPTIONS)) *\n",
    "               (len(reducer_labels) + 1) + .5)\n",
    "\n",
    "plt.figure()\n",
    "COLORS = ['tomato', 'darkolivegreen', 'lightsteelblue']\n",
    "for i, (label, reducer_scores) in enumerate(zip(reducer_labels, mean_scores)):\n",
    "    plt.bar(bar_offsets + i, reducer_scores, label=label, color=COLORS[i])\n",
    "\n",
    "plt.title(\"Comparing feature reduction techniques\")\n",
    "plt.xlabel('Reduced number of features')\n",
    "plt.xticks(bar_offsets + len(reducer_labels) / 2, N_FEATURES_OPTIONS)\n",
    "plt.ylabel('Classification accuracy')\n",
    "plt.ylim((0, 1))\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Learning Curves on the Model with Training and Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning curves\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "\n",
    "def plot_learning_curve(estimator, name, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title('Learning Curves for ' + name)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"No. Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"b\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"b\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "\n",
    "estimator = LogisticRegression(C=0.1, penalty='l1', max_iter=100)\n",
    "plot_learning_curve(estimator, 'Tuned Logistic Regression', X_train, y_train)\n",
    "plt.rcParams['figure.figsize'] = (7, 7)\n",
    "plt.show()\n",
    "estimator = SVC(C=100, gamma=0.01, kernel='rbf')\n",
    "plot_learning_curve(estimator, 'Tuned SVM', X_train, y_train)\n",
    "plt.rcParams['figure.figsize'] = (7, 7)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Model Selection, Training on Entire Train set and Estimating on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn import metrics\n",
    "# train and test classifiers\n",
    "\n",
    "\n",
    "def train_and_test(clf):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "    print(\"classification report:\")\n",
    "    print(metrics.classification_report(y_test, pred))\n",
    "    print()\n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    return clf_descr, score, train_time, test_time\n",
    "\n",
    "\n",
    "results = []\n",
    "for classifier, name in (\n",
    "    (LogisticRegression(\n",
    "        C=0.1, penalty='l1', max_iter=100), \"Logistic Regressin\"), (Perceptron(\n",
    "            alpha=0.001, max_iter=100), \"Perceptron\"), (LinearDiscriminantAnalysis(\n",
    "                tol=0.001), \"LDA\"), (GaussianNB(), \"Naive Bayes\"), (SVC(\n",
    "                    C=100, gamma=0.01, kernel='rbf'), \"SVM\")):\n",
    "    print('=' * 80)\n",
    "    print(name)\n",
    "    results.append(train_and_test(classifier))\n",
    "\n",
    "    \n",
    "indices = np.arange(len(results))\n",
    "results = [[x[i] for x in results] for i in range(4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Plotting ROC Curves on Trained Models on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "lr = LogisticRegression(C=0.1, penalty='l1', max_iter=150)\n",
    "lr.fit(X_train, y_train)\n",
    "lrpreds = lr.predict_proba(X_test)[:,1]\n",
    "lr_fpr, lr_tpr, _ = metrics.roc_curve(y_test, lrpreds)\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(lr_fpr, lr_tpr, color='darkorange',\n",
    "         lw=lw)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.01])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.rcParams['figure.figsize'] = (5,5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 8. Using Other Algorithms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# prepare models\n",
    "models = []\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('Bag', BaggingClassifier(DecisionTreeClassifier(),100, random_state=7)))\n",
    "models.append(('RF', RandomForestClassifier(100, max_features=5)))\n",
    "models.append(('Bo', AdaBoostClassifier(DecisionTreeClassifier(),100, random_state=7)))\n",
    "# create a voting estimation \n",
    "estimators = []\n",
    "estimators.append(('logistic',LogisticRegression()))\n",
    "estimators.append(('NB',  GaussianNB()))\n",
    "models.append(('ELE',VotingClassifier(estimators, voting='soft')))\n",
    "\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'roc_auc'\n",
    "# replace with 'accuracy', 'neg_log_loss',.. based on the need\n",
    "for name, model in models:\n",
    "  kfold = KFold(n_splits=10, random_state=7)\n",
    "  cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "  results.append(cv_results)\n",
    "  names.append(name)\n",
    "  msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "  print(msg)\n",
    "# boxplot algorithm comparison\n",
    "fig = pyplot.figure() \n",
    "fig.suptitle('Linear and Non-Linear Algorithm Comparison on Cross-Validation') \n",
    "ax = fig.add_subplot(111) \n",
    "pyplot.boxplot(results) \n",
    "ax.set_xticklabels(names) \n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
